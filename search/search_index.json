{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"start-ocr Docs","text":"<p>Caveat</p> <p>ImageMagick setups vary:</p> <ol> <li><code>homebrew</code>-based installation</li> <li><code>Dockerfile</code> compiles from source</li> <li>Github action <code>main.yml</code></li> </ol> <p>This makes some tests janky so have to be a bit creative, e.g.:</p> Sample docstring<pre><code>&gt;&gt;&gt; contours = get_contours(im, (10,10))\n&gt;&gt;&gt; len(contours) in [222,223] # So one installation outputs 222 and the other 223\nTrue\n</code></pre> <p>Ideally, this would consistent. Will have to circle back on this another time.</p>"},{"location":"#sample-pdf","title":"Sample PDF","text":"<p>A simple file is included in the <code>/tests</code> folder to demonstrate certain functions:</p> <p></p>"},{"location":"#fetchget_page_and_img","title":"<code>fetch.get_page_and_img()</code>","text":"<p>Each page of a PDF file, can be opened and cropped via <code>pdfplumber</code>. To parse, it's necessary to convert the pdf to an <code>opencv</code> compatible-image format (i.e. <code>np.ndarray</code>). This function converts a <code>Path</code> object into a pair of objects:</p> <ol> <li>the first part is a <code>pdfplumber.Page</code></li> <li>the second part is an openCV image, i.e. <code>np.ndarray</code></li> </ol> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0) # 0 marks the first page\n&gt;&gt;&gt; page.page_number # the first page\n1\n&gt;&gt;&gt; isinstance(page, Page)\nTrue\n&gt;&gt;&gt; isinstance(im, np.ndarray)\nTrue\n&gt;&gt;&gt; page.pdf.close()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>pdfpath</code> <code>str | Path</code> <p>Path to the PDF file.</p> required <code>index</code> <code>int</code> <p>Zero-based index that determines the page number.</p> required <p>Returns:</p> Type Description <code>tuple[Page, ndarray]</code> <p>tuple[Page, np.ndarray]: Page identified by <code>index</code>  with image of the page  (in np format) that can be manipulated.</p> Source code in <code>src/start_ocr/fetch.py</code> Python<pre><code>def get_page_and_img(pdfpath: str | Path, index: int) -&gt; tuple[Page, np.ndarray]:\n    \"\"\"Each page of a PDF file, can be opened and cropped via `pdfplumber`.\n    To parse, it's necessary to convert the pdf to an `opencv` compatible-image format\n    (i.e. `np.ndarray`). This function converts a `Path` object into a pair of objects:\n\n    1. the first part is a `pdfplumber.Page`\n    2. the second part is an openCV image, i.e. `np.ndarray`\n\n    Examples:\n        &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0) # 0 marks the first page\n        &gt;&gt;&gt; page.page_number # the first page\n        1\n        &gt;&gt;&gt; isinstance(page, Page)\n        True\n        &gt;&gt;&gt; isinstance(im, np.ndarray)\n        True\n        &gt;&gt;&gt; page.pdf.close()\n\n    Args:\n        pdfpath (str | Path): Path to the PDF file.\n        index (int): Zero-based index that determines the page number.\n\n    Returns:\n        tuple[Page, np.ndarray]: Page identified by `index`  with image of the\n            page  (in np format) that can be manipulated.\n    \"\"\"  # noqa: E501\n    with pdfplumber.open(pdfpath) as pdf:\n        page = pdf.pages[index]\n        img = get_img_from_page(page)\n        return page, img\n</code></pre>"},{"location":"#sliceget_contours","title":"<code>slice.get_contours()</code>","text":""},{"location":"#mental-model","title":"Mental Model","text":"<pre><code>flowchart LR\n    pdf --&gt; im[image]\n    im --&gt; c[contours]\n    c --&gt; c1[contour 1: the header]\n    c --&gt; c2[contour 2: the line below the header]\n    c --&gt; c3[contour 3: the footer]</code></pre>"},{"location":"#conversion","title":"Conversion","text":"<p>Converting the pdf to an image format enables <code>get_contours()</code>. Contours can be thought of as tiny fragments within the document that delineate where certain objects in the document are located.</p>"},{"location":"#show-contours","title":"Show Contours","text":"<p>To demonstrate <code>get_contours</code>, I created a helper <code>show_contours</code> which just prints out where the contours are found given a rectangle size that we want to use for the image.</p> <p><code>100 x 100</code> yields 7 contours</p> 100 x 100<pre><code>&gt;&gt;&gt; from start_ocr import get_page_and_img, show_contours\n&gt;&gt;&gt; page, img = get_page_and_img(pdfpath=p, index=0)\n&gt;&gt;&gt; rectangle_size_lg = (100,100)\n&gt;&gt;&gt; contours = show_contours(img, rectangle_size_lg) # runs get_contours()\n</code></pre> <code>dilated</code> <code>contours</code> <p><code>10 x 10</code> yields 285 contours</p> 10 x 10<pre><code>&gt;&gt;&gt; from start_ocr import get_page_and_img, show_contours\n&gt;&gt;&gt; page, img = get_page_and_img(pdfpath=p, index=0)\n&gt;&gt;&gt; rectangle_size_sm = (10,10)\n&gt;&gt;&gt; contours = show_contours(img, rectangle_size_sm) # runs get_contours()\n</code></pre> <code>dilated</code> 285 <code>contours</code>"},{"location":"#get_contours","title":"<code>get_contours()</code>","text":"<p>Explaining dilation and contours.</p> <p>The function follows the strategy outlined in Python Tutorials for Digital Humanities. A good explanation on how dilation works is found in this Stack Overflow answer by @nathancy.</p> <p>Using tiny <code>rectangle_size</code> of the format <code>(width, height)</code>, create a dilated version of the image <code>im</code>. The contours found are outputed by this function.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from start_ocr.fetch import get_page_and_img\n&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n&gt;&gt;&gt; contours = get_contours(im, (50,50))\n&gt;&gt;&gt; len(contours)\n15\n&gt;&gt;&gt; contours = get_contours(im, (10,10))\n&gt;&gt;&gt; len(contours) in [222,223]\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>im</code> <code>ndarray</code> <p>The opencv formatted image</p> required <code>rectangle_size</code> <code>tuple[int, int]</code> <p>The width and height of the contours to make</p> required <code>test_dilation</code> <code>bool</code> <p>If <code>test_dilation</code> is <code>True</code>, a file will be created in the path represented in <code>test_dilated_image</code> to illustrate what the \"diluted\" image looks like.. Defaults to False.</p> <code>False</code> <code>test_dilated_image</code> <code>str | None</code> <p>description. Defaults to \"temp/dilated.png\".</p> <code>'temp/dilated.png'</code> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The contours found based on the specified structuring element</p> Source code in <code>src/start_ocr/slice.py</code> Python<pre><code>def get_contours(\n    im: np.ndarray,\n    rectangle_size: tuple[int, int],\n    test_dilation: bool = False,\n    test_dilated_image: str | None = \"temp/dilated.png\",\n) -&gt; list:\n    \"\"\"Using tiny `rectangle_size` of the format `(width, height)`, create a dilated version\n    of the image `im`. The contours found are outputed by this function.\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from start_ocr.fetch import get_page_and_img\n        &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n        &gt;&gt;&gt; contours = get_contours(im, (50,50))\n        &gt;&gt;&gt; len(contours)\n        15\n        &gt;&gt;&gt; contours = get_contours(im, (10,10))\n        &gt;&gt;&gt; len(contours) in [222,223]\n        True\n\n    Args:\n        im (np.ndarray): The opencv formatted image\n        rectangle_size (tuple[int, int]): The width and height of the contours to make\n        test_dilation (bool, optional): If `test_dilation` is `True`, a file will be created in the path represented in `test_dilated_image` to illustrate what the \"diluted\" image looks like.. Defaults to False.\n        test_dilated_image (str | None, optional): _description_. Defaults to \"temp/dilated.png\".\n\n    Returns:\n        list: The contours found based on the specified structuring element\n\n    \"\"\"  # noqa: E501\n    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n    blur = cv2.GaussianBlur(gray, (7, 7), 0)\n    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, rectangle_size)\n    dilate = cv2.dilate(thresh, kernel, iterations=1)\n    if test_dilation and test_dilated_image:\n        cv2.imwrite(test_dilated_image, dilate)\n    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n    return sorted(cnts, key=lambda x: cv2.boundingRect(x)[1])\n</code></pre>"},{"location":"#filtering-contours","title":"Filtering contours","text":"<p>Each contour can be filtered further to arrive at rectangles that meet the filter criteria:</p> <pre><code>flowchart TB\n    c1[contour 1] --&gt; f[filter]\n    c2[contour 2] --&gt; f\n    c3[contour 3] --&gt; f\n    f --&gt; c2x[filtered contour 1]</code></pre> <p>For instance, we can try looking for a long horizontal line matching some criteria:</p> <ol> <li>If we imagine the page to be divided into 3 equal vertical slices, the line must start at the first slice and end in the third slice.</li> <li>If we imagine the page width to be of X width, X/2 is simply half this width.</li> </ol> <p>Let's say we want to look for a line that is greater than half the page width (2), positioned with edges along (1):</p> Filtering mechanism in practice<pre><code>imgs = []\npage, img = get_page_and_img(pdfpath=p, index=0)\ncontours = get_contours(img, (10, 10), test_dilation=True)\n_, im_w, _ = img.shape\nfor cnt in contours:\n    x, y, w, h = cv2.boundingRect(cnt)  # unpack each contour\n    filtering_criteria = [\n        w &gt; im_w / 2,  # width greater than half\n        x &lt; im_w / 3,  # edge of line on first third vertical slice\n        (x + w) &gt; im_w * (2 / 3),  # edge of line on last third vertical slice\n    ]\n    if all(filtering_criteria):\n        obj = CoordinatedImage(img, x, y, w, h)\n        obj.greenbox()\n        imgs.append(obj)\ncv2.imwrite(\"temp/boxes.png\", img)\n</code></pre> <p>The <code>CoordinatedImage</code> is a data structure to compute related values of <code>x</code>, <code>y</code>, <code>w</code>, and <code>h</code>.</p>"},{"location":"components/","title":"Page Components","text":""},{"location":"components/#header","title":"Header","text":""},{"location":"components/#page-y-axis-start","title":"Page Y-Axis Start","text":"<p>The header represents non-title page content above the main content.</p> <p>The terminating header line is a non-visible line that separates the decision's header from its main content. We'll use a typographic bottom of the header to signify this line.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from start_ocr import get_page_and_img\n&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 1)\n&gt;&gt;&gt; int(get_header_line(im, page)) in [76, 77]\nTrue\n&gt;&gt;&gt; page.pdf.close()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>im</code> <code>ndarray</code> <p>The full page image</p> required <code>page</code> <code>Page</code> <p>The pdfplumber page</p> required <p>Returns:</p> Type Description <code>int | float | None</code> <p>float | None: Y-axis point (pdfplumber point) at bottom of header</p> Source code in <code>src/start_ocr/components.py</code> Python<pre><code>def get_header_line(im: np.ndarray, page: Page) -&gt; int | float | None:\n    \"\"\"The header represents non-title page content above the main content.\n\n    The terminating header line is a non-visible line that separates the\n    decision's header from its main content. We'll use a typographic bottom\n    of the header to signify this line.\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from start_ocr import get_page_and_img\n        &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 1)\n        &gt;&gt;&gt; int(get_header_line(im, page)) in [76, 77]\n        True\n        &gt;&gt;&gt; page.pdf.close()\n\n    Args:\n        im (numpy.ndarray): The full page image\n        page (Page): The pdfplumber page\n\n    Returns:\n        float | None: Y-axis point (pdfplumber point) at bottom of header\n    \"\"\"  # noqa: E501\n    im_h, im_w, _ = im.shape\n    if hd := get_header_upper_right(im):\n        _, y, _, h = hd\n        header_end = (y + h) / im_h\n        terminal = header_end * page.height\n        return terminal\n    return None\n</code></pre>"},{"location":"components/#upper-right","title":"Upper Right","text":"<p>The header represents non-title page content above the main content.</p> <p>It usually consists of three items:</p> Item Label Test PDF 1 Indicator text <code>Indicator</code> 2 Page number <code>1</code> 3 Some other detail <code>xyzabc123</code> <p>This detects Item (3) which implies that it is the in upper right quarter of the document:</p> Python<pre><code>x &gt; im_w / 2  # ensures that it is on the right side of the page\ny &lt;= im_h * 0.2  # ensures that it is on the top quarter of the page\n</code></pre> <p>Item (3) is the only one above that is likely to have a second vertical line, hence choosing this as the the typographic bottom for the header makes sense.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from start_ocr import get_page_and_img\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 1)\n&gt;&gt;&gt; isinstance(get_header_upper_right(im), tuple)\nTrue\n&gt;&gt;&gt; page.pdf.close()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>im</code> <code>ndarray</code> <p>The full page image</p> required <p>Returns:</p> Type Description <code>tuple[int, int, int, int] | None</code> <p>tuple[int, int, int, int] | None: The coordinates of the docket, if found.</p> Source code in <code>src/start_ocr/components.py</code> Python<pre><code>def get_header_upper_right(\n    im: np.ndarray,\n) -&gt; tuple[int, int, int, int] | None:\n    \"\"\"The header represents non-title page content above the main content.\n\n    It usually consists of three items:\n\n    Item | Label | Test PDF\n    --:|:--|:--\n    1 | Indicator text | `Indicator`\n    2 | Page number | `1`\n    3 | Some other detail | `xyzabc123`\n\n    This detects Item (3) which implies that it is the in upper right quarter\n    of the document:\n\n    ```py\n    x &gt; im_w / 2  # ensures that it is on the right side of the page\n    y &lt;= im_h * 0.2  # ensures that it is on the top quarter of the page\n    ```\n\n    Item (3) is the only one above that is likely to have a second vertical line,\n    hence choosing this as the the typographic bottom for the header makes sense.\n\n    Examples:\n        &gt;&gt;&gt; from start_ocr import get_page_and_img\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 1)\n        &gt;&gt;&gt; isinstance(get_header_upper_right(im), tuple)\n        True\n        &gt;&gt;&gt; page.pdf.close()\n\n    Args:\n        im (numpy.ndarray): The full page image\n\n    Returns:\n        tuple[int, int, int, int] | None: The coordinates of the docket, if found.\n    \"\"\"  # noqa: E501\n    im_h, im_w, _ = im.shape\n    for cnt in get_contours(im, (50, 50)):\n        x, y, w, h = cv2.boundingRect(cnt)\n        if x &gt; im_w / 2 and y &lt;= im_h * 0.25 and w &gt; 200:\n            return x, y, w, h\n    return None\n</code></pre>"},{"location":"components/#page-number","title":"Page Number","text":"<p>Aside from the first page, which should always be <code>1</code>, this function gets the first matching digit in the header's text. If no such digit is round, return 0.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; import pdfplumber\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from start_ocr import get_img_from_page\n&gt;&gt;&gt; x = Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\"\n&gt;&gt;&gt; pdf = pdfplumber.open(x)\n&gt;&gt;&gt; page = pdf.pages[1] # page 2\n&gt;&gt;&gt; im = get_img_from_page(page)\n&gt;&gt;&gt; header_line = get_header_line(im, page)\n&gt;&gt;&gt; get_page_num(page, header_line)\n2\n&gt;&gt;&gt; pdf.close()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>Page</code> <p>The pdfplumber page</p> required <code>header_line</code> <code>int | float</code> <p>The value retrieved from <code>get_header_line()</code></p> required <p>Returns:</p> Type Description <code>int</code> <p>int | None: The page number, if found</p> Source code in <code>src/start_ocr/components.py</code> Python<pre><code>def get_page_num(page: Page, header_line: int | float) -&gt; int:\n    \"\"\"Aside from the first page, which should always be `1`,\n    this function gets the first matching digit in the header's text.\n    If no such digit is round, return 0.\n\n    Examples:\n        &gt;&gt;&gt; import pdfplumber\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from start_ocr import get_img_from_page\n        &gt;&gt;&gt; x = Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\"\n        &gt;&gt;&gt; pdf = pdfplumber.open(x)\n        &gt;&gt;&gt; page = pdf.pages[1] # page 2\n        &gt;&gt;&gt; im = get_img_from_page(page)\n        &gt;&gt;&gt; header_line = get_header_line(im, page)\n        &gt;&gt;&gt; get_page_num(page, header_line)\n        2\n        &gt;&gt;&gt; pdf.close()\n\n    Args:\n        page (Page): The pdfplumber page\n        header_line (int | float): The value retrieved from `get_header_line()`\n\n    Returns:\n        int | None: The page number, if found\n    \"\"\"\n    if page.page_number == 1:\n        return 1  # The first page should always be page 1\n\n    box = (0, 0, page.width, header_line)\n    header = page.crop(box, relative=False, strict=True)\n    texts = header.extract_text(layout=True, keep_blank_chars=True).split()\n    for text in texts:\n        if text.isdigit() and len(text) &lt;= 3:\n            return int(text)  # Subsequent pages shall be based on the header\n\n    return 0  # 0 implies\n</code></pre>"},{"location":"components/#lines","title":"Lines","text":""},{"location":"components/#bodyline","title":"Bodyline","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Each page may be divided into lines which, for our purposes, will refer to an arbitrary segmentation of text based on regex parameters.</p> Field Type Description <code>num</code> int Order in the page <code>line</code> str The text found based on segmentation Source code in <code>src/start_ocr/components.py</code> Python<pre><code>class Bodyline(NamedTuple):\n    \"\"\"Each page may be divided into lines which, for our purposes,\n    will refer to an arbitrary segmentation of text based on regex parameters.\n\n    Field | Type | Description\n    --:|:--:|:--\n    `num` | int | Order in the page\n    `line` | str | The text found based on segmentation\n    \"\"\"\n\n    page_num: int\n    order_num: int\n    line: str\n\n    @classmethod\n    def split(cls, prelim_lines: list[str], page_num: int) -&gt; list[Self]:\n        \"\"\"Get paragraphs using regex `\\\\s{10,}(?=[A-Z])`\n        implying many spaces before a capital letter then\n        remove new lines contained in non-paragraph lines.\n\n        Args:\n            prelim_lines (list[str]): Previously split text\n\n        Returns:\n            list[Self]: Bodylines of segmented text\n        \"\"\"\n        lines = []\n        for order_num, par in enumerate(prelim_lines, start=1):\n            obj = cls(\n                page_num=page_num,\n                order_num=order_num,\n                line=line_break.sub(\" \", par).strip(),\n            )\n            lines.append(obj)\n        lines.sort(key=lambda obj: obj.order_num)\n        return lines\n</code></pre>"},{"location":"components/#start_ocr.components.Bodyline-functions","title":"Functions","text":""},{"location":"components/#start_ocr.components.Bodyline.split","title":"<code>split(prelim_lines, page_num)</code>  <code>classmethod</code>","text":"<p>Get paragraphs using regex <code>\\s{10,}(?=[A-Z])</code> implying many spaces before a capital letter then remove new lines contained in non-paragraph lines.</p> <p>Parameters:</p> Name Type Description Default <code>prelim_lines</code> <code>list[str]</code> <p>Previously split text</p> required <p>Returns:</p> Type Description <code>list[Self]</code> <p>list[Self]: Bodylines of segmented text</p> Source code in <code>src/start_ocr/components.py</code> Python<pre><code>@classmethod\ndef split(cls, prelim_lines: list[str], page_num: int) -&gt; list[Self]:\n    \"\"\"Get paragraphs using regex `\\\\s{10,}(?=[A-Z])`\n    implying many spaces before a capital letter then\n    remove new lines contained in non-paragraph lines.\n\n    Args:\n        prelim_lines (list[str]): Previously split text\n\n    Returns:\n        list[Self]: Bodylines of segmented text\n    \"\"\"\n    lines = []\n    for order_num, par in enumerate(prelim_lines, start=1):\n        obj = cls(\n            page_num=page_num,\n            order_num=order_num,\n            line=line_break.sub(\" \", par).strip(),\n        )\n        lines.append(obj)\n    lines.sort(key=lambda obj: obj.order_num)\n    return lines\n</code></pre>"},{"location":"components/#footnote","title":"Footnote","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Each page may contain an annex which consists of footnotes. Note that this is based on a imperfect use of regex to detect the footnote number <code>fn_id</code> and its corresponding text <code>note</code>.</p> Field Type Description <code>fn_id</code> int Footnote number <code>note</code> str The text found based on segmentation of footnotes Source code in <code>src/start_ocr/components.py</code> Python<pre><code>class Footnote(NamedTuple):\n    \"\"\"Each page may contain an annex which consists of footnotes. Note\n    that this is based on a imperfect use of regex to detect the footnote\n    number `fn_id` and its corresponding text `note`.\n\n    Field | Type | Description\n    --:|:--:|:--\n    `fn_id` | int | Footnote number\n    `note` | str | The text found based on segmentation of footnotes\n    \"\"\"\n\n    page_num: int\n    fn_id: int\n    note: str\n\n    @classmethod\n    def extract_notes(cls, text: str, page_num: int) -&gt; list[Self]:\n        \"\"\"Get footnote digits using regex `\\\\n\\\\s+(?P&lt;fn&gt;\\\\d+)(?=\\\\s+[A-Z])`\n        then for each matching span, the start span becomes the anchor\n        for the balance of the text for each remaining foornote in the while\n        loop. The while loop extraction must use `.pop()` where the last\n        item is removed first.\n\n        Args:\n            text (str): Text that should be convertible to footnotes based on regex\n\n        Returns:\n            list[Self]: Footnotes separated by digits.\n        \"\"\"\n        notes = []\n        while True:\n            matches = list(footnote_nums.finditer(text))\n            if not matches:\n                break\n            note = matches.pop()  # start from the last\n            footnote_num = int(note.group(\"fn\"))\n            digit_start, digit_end = note.span()\n            footnote_body = text[digit_end:].strip()\n            obj = cls(\n                page_num=page_num,\n                fn_id=footnote_num,\n                note=footnote_body,\n            )\n            notes.append(obj)\n            text = text[:digit_start]\n        notes.sort(key=lambda obj: obj.fn_id)\n        return notes\n</code></pre>"},{"location":"components/#start_ocr.components.Footnote-functions","title":"Functions","text":""},{"location":"components/#start_ocr.components.Footnote.extract_notes","title":"<code>extract_notes(text, page_num)</code>  <code>classmethod</code>","text":"<p>Get footnote digits using regex <code>\\n\\s+(?P&lt;fn&gt;\\d+)(?=\\s+[A-Z])</code> then for each matching span, the start span becomes the anchor for the balance of the text for each remaining foornote in the while loop. The while loop extraction must use <code>.pop()</code> where the last item is removed first.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text that should be convertible to footnotes based on regex</p> required <p>Returns:</p> Type Description <code>list[Self]</code> <p>list[Self]: Footnotes separated by digits.</p> Source code in <code>src/start_ocr/components.py</code> Python<pre><code>@classmethod\ndef extract_notes(cls, text: str, page_num: int) -&gt; list[Self]:\n    \"\"\"Get footnote digits using regex `\\\\n\\\\s+(?P&lt;fn&gt;\\\\d+)(?=\\\\s+[A-Z])`\n    then for each matching span, the start span becomes the anchor\n    for the balance of the text for each remaining foornote in the while\n    loop. The while loop extraction must use `.pop()` where the last\n    item is removed first.\n\n    Args:\n        text (str): Text that should be convertible to footnotes based on regex\n\n    Returns:\n        list[Self]: Footnotes separated by digits.\n    \"\"\"\n    notes = []\n    while True:\n        matches = list(footnote_nums.finditer(text))\n        if not matches:\n            break\n        note = matches.pop()  # start from the last\n        footnote_num = int(note.group(\"fn\"))\n        digit_start, digit_end = note.span()\n        footnote_body = text[digit_end:].strip()\n        obj = cls(\n            page_num=page_num,\n            fn_id=footnote_num,\n            note=footnote_body,\n        )\n        notes.append(obj)\n        text = text[:digit_start]\n    notes.sort(key=lambda obj: obj.fn_id)\n    return notes\n</code></pre>"},{"location":"components/#footer","title":"Footer","text":""},{"location":"components/#annex-existence-as-page-y-axis-ends","title":"Annex Existence as Page Y-Axis End/s","text":"<p>Given an <code>im</code>, detect footnote line of annex and return relevant points in the y-axis as a tuple.</p> Scenario Description y0 y1 Footnote line exists Page contains footnotes int or float int or float signifying end of page Footnote line absent Page does not contain footnotes int or float signifying end of page <code>None</code> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from start_ocr import get_page_and_img\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n&gt;&gt;&gt; res = get_page_end(im, page)\n&gt;&gt;&gt; isinstance(res, tuple)\nTrue\n&gt;&gt;&gt; int(res[0])\n822\n&gt;&gt;&gt; int(res[1])\n879\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>im</code> <code>ndarray</code> <p>the openCV image that may contain a footnote line</p> required <code>page</code> <code>Page</code> <p>the pdfplumber.page.Page based on <code>im</code></p> required <p>Returns:</p> Type Description <code>tuple[float, float | None]</code> <p>tuple[float, float | None]: Annex line's y-axis (if it exists) and the page's end content line.</p> Source code in <code>src/start_ocr/components.py</code> Python<pre><code>def get_page_end(im: np.ndarray, page: Page) -&gt; tuple[float, float | None]:\n    \"\"\"Given an `im`, detect footnote line of annex and return relevant points in the y-axis as a tuple.\n\n    Scenario | Description | y0 | y1\n    :--:|:-- |:--:|:--:\n    Footnote line exists | Page contains footnotes | int or float | int or float signifying end of page\n    Footnote line absent | Page does not contain footnotes | int or float signifying end of page | `None`\n\n    Examples:\n        &gt;&gt;&gt; from start_ocr import get_page_and_img\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n        &gt;&gt;&gt; res = get_page_end(im, page)\n        &gt;&gt;&gt; isinstance(res, tuple)\n        True\n        &gt;&gt;&gt; int(res[0])\n        822\n        &gt;&gt;&gt; int(res[1])\n        879\n\n    Args:\n        im (numpy.ndarray): the openCV image that may contain a footnote line\n        page (Page): the pdfplumber.page.Page based on `im`\n\n    Returns:\n        tuple[float, float | None]: Annex line's y-axis (if it exists) and the page's end content line.\n    \"\"\"  # noqa: E501\n    y1 = PERCENT_OF_MAX_PAGE * page.height\n    im_h, _, _ = im.shape\n    if lines := footnote_lines(im):\n        fn_line_end = lines[0].y / im_h\n        y0 = fn_line_end * page.height\n        return y0, y1\n    return y1, None\n</code></pre>"},{"location":"components/#page-width-lines","title":"Page Width Lines","text":"<p>Filter long horizontal lines:</p> <ol> <li>Edges of lines must be:<ul> <li>on the left of the page; and</li> <li>on the right of the page</li> </ul> </li> <li>Each line must be at least 1/2 the page width</li> </ol> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from start_ocr import get_page_and_img\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n&gt;&gt;&gt; res = page_width_lines(im)\n&gt;&gt;&gt; len(res) # only one image matches the filter\n3\n</code></pre> Source code in <code>src/start_ocr/components.py</code> Python<pre><code>def page_width_lines(im: np.ndarray) -&gt; list[CoordinatedImage]:\n    \"\"\"Filter long horizontal lines:\n\n    1. Edges of lines must be:\n        - on the left of the page; and\n        - on the right of the page\n    2. Each line must be at least 1/2 the page width\n\n    Examples:\n        &gt;&gt;&gt; from start_ocr import get_page_and_img\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n        &gt;&gt;&gt; res = page_width_lines(im)\n        &gt;&gt;&gt; len(res) # only one image matches the filter\n        3\n    \"\"\"  # noqa: E501\n    _, im_w, _ = im.shape\n    results = []\n    contours = get_contours(\n        im=im,\n        rectangle_size=(100, 100),\n        test_dilation=True,\n        test_dilated_image=\"temp/dilated.png\",\n    )\n    for contour in contours:\n        x, y, w, h = cv2.boundingRect(contour)\n        contoured = CoordinatedImage(im, x, y, w, h)\n        contoured.redbox()\n        filtering_criteria = [\n            w &gt; im_w / 2,  # width greater than half\n            x &lt; im_w / 3,  # edge of line on first third\n            (x + w) &gt; im_w * (2 / 3),  # edge of line on last third\n        ]\n        if all(filtering_criteria):\n            obj = CoordinatedImage(im, x, y, w, h)\n            obj.greenbox()\n            results.append(obj)\n    cv2.imwrite(\"temp/boxes.png\", im)\n    return results\n</code></pre>"},{"location":"content/","title":"Content","text":"<p>Metadata of a single content page.</p> Field Description <code>page_num</code> Page number <code>body</code> Main content above an annex, if existing <code>segments</code> Segments of the <code>body</code>'s text in the given <code>page_num</code> <code>annex</code> Portion of page containing the footnotes; some pages are annex-free <code>footnotes</code> Each footnote item in the <code>annex</code>'s text in the given <code>page_num</code> Source code in <code>src/start_ocr/content.py</code> Python<pre><code>@dataclass\nclass Content:\n    \"\"\"Metadata of a single content page.\n\n    Field | Description\n    --:|:--\n    `page_num` | Page number\n    `body` | Main content above an annex, if existing\n    `segments` | Segments of the `body`'s text in the given `page_num`\n    `annex` | Portion of page containing the footnotes; some pages are annex-free\n    `footnotes` | Each footnote item in the `annex`'s text in the given `page_num`\n    \"\"\"  # noqa: E501\n\n    page_num: int\n    body: CroppedPage\n    body_text: str\n    annex: CroppedPage | None = None\n    annex_text: str | None = None\n    segments: list[Bodyline] = field(default_factory=list)\n    footnotes: list[Footnote] = field(default_factory=list)\n\n    def __post_init__(self):\n        alpha = paragraph_break.split(self.body_text)\n        beta = self.body_text.split(\"\\n\\n\")\n        candidates = alpha or beta\n        self.segments = Bodyline.split(candidates, self.page_num)\n        if self.annex and self.annex_text:\n            self.footnotes = Footnote.extract_notes(self.annex_text, self.page_num)\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Content Page: {self.page_num}&gt;\"\n\n    @classmethod\n    def set(\n        cls,\n        page: Page,\n        start_y: float | int | None = None,\n        end_y: float | int | None = None,\n    ) -&gt; Self:\n        \"\"\"\n        A `header_line` (related to `start_y`) and `page_line` (related to `end_y`) are utilized as local variables in this function.\n\n        The `header_line` is the imaginary line at the top of the page. If the `start_y` is supplied, it means that the `header_line` no longer needs to be calculated.\n\n        The `page_line` is the imaginary line at the bottom of the page. If the `end_y` is supplied, it means that the calculated `page_line` ought to be replaced.\n\n        The presence of a `header_line` and a `page_endline` determine what to extract as content from a given `page`.\n\n        Args:\n            page (Page): The pdfplumber page to evaluate\n            start_y (float | int | None, optional): If present, refers to The y-axis point of the starter page. Defaults to None.\n            end_y (float | int | None, optional): If present, refers to The y-axis point of the ender page. Defaults to None.\n\n        Returns:\n            Self: Page with individual components mapped out.\n        \"\"\"  # noqa: E501\n        im = get_img_from_page(page)\n\n        header_line = start_y or get_header_line(im, page)\n        if not header_line:\n            raise Exception(f\"No header line in {page.page_number=}\")\n\n        end_of_content, e = get_page_end(im, page)\n        page_line = end_y or end_of_content\n\n        body = PageCut.set(page=page, y0=header_line, y1=page_line)\n        body_text = paged_text(body) or imaged_text(body)\n        annex = None\n        annex_text = None\n\n        if e:\n            annex = PageCut.set(page=page, y0=end_of_content, y1=e)\n            annex_text = paged_text(annex) or imaged_text(annex)\n\n        return cls(\n            page_num=get_page_num(page, header_line),\n            body=body,\n            body_text=body_text,\n            annex=annex,\n            annex_text=annex_text,\n        )\n</code></pre>"},{"location":"content/#start_ocr.content.Content-functions","title":"Functions","text":""},{"location":"content/#start_ocr.content.Content.set","title":"<code>set(page, start_y=None, end_y=None)</code>  <code>classmethod</code>","text":"<p>A <code>header_line</code> (related to <code>start_y</code>) and <code>page_line</code> (related to <code>end_y</code>) are utilized as local variables in this function.</p> <p>The <code>header_line</code> is the imaginary line at the top of the page. If the <code>start_y</code> is supplied, it means that the <code>header_line</code> no longer needs to be calculated.</p> <p>The <code>page_line</code> is the imaginary line at the bottom of the page. If the <code>end_y</code> is supplied, it means that the calculated <code>page_line</code> ought to be replaced.</p> <p>The presence of a <code>header_line</code> and a <code>page_endline</code> determine what to extract as content from a given <code>page</code>.</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>Page</code> <p>The pdfplumber page to evaluate</p> required <code>start_y</code> <code>float | int | None</code> <p>If present, refers to The y-axis point of the starter page. Defaults to None.</p> <code>None</code> <code>end_y</code> <code>float | int | None</code> <p>If present, refers to The y-axis point of the ender page. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>Page with individual components mapped out.</p> Source code in <code>src/start_ocr/content.py</code> Python<pre><code>@classmethod\ndef set(\n    cls,\n    page: Page,\n    start_y: float | int | None = None,\n    end_y: float | int | None = None,\n) -&gt; Self:\n    \"\"\"\n    A `header_line` (related to `start_y`) and `page_line` (related to `end_y`) are utilized as local variables in this function.\n\n    The `header_line` is the imaginary line at the top of the page. If the `start_y` is supplied, it means that the `header_line` no longer needs to be calculated.\n\n    The `page_line` is the imaginary line at the bottom of the page. If the `end_y` is supplied, it means that the calculated `page_line` ought to be replaced.\n\n    The presence of a `header_line` and a `page_endline` determine what to extract as content from a given `page`.\n\n    Args:\n        page (Page): The pdfplumber page to evaluate\n        start_y (float | int | None, optional): If present, refers to The y-axis point of the starter page. Defaults to None.\n        end_y (float | int | None, optional): If present, refers to The y-axis point of the ender page. Defaults to None.\n\n    Returns:\n        Self: Page with individual components mapped out.\n    \"\"\"  # noqa: E501\n    im = get_img_from_page(page)\n\n    header_line = start_y or get_header_line(im, page)\n    if not header_line:\n        raise Exception(f\"No header line in {page.page_number=}\")\n\n    end_of_content, e = get_page_end(im, page)\n    page_line = end_y or end_of_content\n\n    body = PageCut.set(page=page, y0=header_line, y1=page_line)\n    body_text = paged_text(body) or imaged_text(body)\n    annex = None\n    annex_text = None\n\n    if e:\n        annex = PageCut.set(page=page, y0=end_of_content, y1=e)\n        annex_text = paged_text(annex) or imaged_text(annex)\n\n    return cls(\n        page_num=get_page_num(page, header_line),\n        body=body,\n        body_text=body_text,\n        annex=annex,\n        annex_text=annex_text,\n    )\n</code></pre>"},{"location":"coordinates/","title":"Coordinated Image","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Each filtered item can be wrapped around this data structure where each will have its own dimensions, that can be used in relation to the original image (<code>im</code>):</p> raw dimension definition <code>x</code> x-axis position marking the start of the filtered item <code>y</code> y-axis position marking the start of the filtered item <code>w</code> x-axis based _w_idth of the filtered item <code>h</code> y-axis based _h_eight of the filtered item <p>This \"coordinates\" setup enables the calculation of the end positions (of the filtered items) as properties, e.g.:</p> calculated dimension calculation definition <code>x1</code> <code>x + w</code> x-axis position marking the end of the filtered item <code>y1</code> <code>y + h</code> y-axis position marking the end of the filtered item Source code in <code>src/start_ocr/coordinates.py</code> Python<pre><code>class CoordinatedImage(NamedTuple):\n    \"\"\"Each filtered item can be wrapped around this data structure where each will have its own\n    dimensions, that can be used in relation to the original image (`im`):\n\n    raw dimension | definition\n    --:|:--\n    `x` | _x_-axis position marking the start of the filtered item\n    `y` | _y_-axis position marking the start of the filtered item\n    `w` | x-axis based _w_idth of the filtered item\n    `h` | y-axis based _h_eight of the filtered item\n\n    This \"coordinates\" setup enables the calculation of the end positions (of the\n    filtered items) as properties, e.g.:\n\n    calculated dimension | calculation | definition\n    --:|:--:|:--\n    `x1` | `x + w` | x-axis position marking the end of the filtered item\n    `y1` | `y + h` | y-axis position marking the end of the filtered item\n    \"\"\"  # noqa: E501\n\n    im: ndarray\n    x: float\n    y: float\n    w: float\n    h: float\n\n    @property\n    def x1(self):\n        \"\"\"X-axis position marking end of filtered item.\"\"\"\n        return self.x + self.w\n\n    @property\n    def y1(self):\n        \"\"\"Y-axis position marking end of filtered item.\"\"\"\n        return self.y + self.h\n\n    @property\n    def upper_left_point(self) -&gt; tuple[float, float]:\n        \"\"\"The upper left point of a rectangle.\"\"\"\n        return (self.x, self.y)\n\n    @property\n    def lower_right_point(self) -&gt; tuple[float, float]:\n        \"\"\"The lower right point of a rectangle.\"\"\"\n        return (self.x1, self.y1)\n\n    @property\n    def fragment(self) -&gt; ndarray:\n        \"\"\"The slice of an image with the filtered coordinates in the format:\n        image [pt1, pt2] where:\n\n        1. pt1 = from point y to point y1\n        1. pt2 = from point x to point x1\n        \"\"\"\n        return self.im[self.y : self.y1, self.x : self.x1]\n\n    def greenbox(self):\n        \"\"\"Add a \"green box\" to the image where the box area is represented by the\n        diagonal of pt1 and pt2: pt1 being the upper left point and pt2 being\n        the lower right point of the rectangle.\"\"\"\n        return cv2.rectangle(\n            img=self.im,\n            pt1=self.upper_left_point,\n            pt2=self.lower_right_point,\n            color=GREEN,\n            thickness=2,\n        )\n\n    def redbox(self):\n        \"\"\"Add a \"green box\" to the image where the box area is represented by the\n        diagonal of pt1 and pt2: pt1 being the upper left point and pt2 being\n        the lower right point of the rectangle.\"\"\"\n        return cv2.rectangle(\n            img=self.im,\n            pt1=self.upper_left_point,\n            pt2=self.lower_right_point,\n            color=PURPLE,\n            thickness=1,\n        )\n</code></pre>"},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage-attributes","title":"Attributes","text":""},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage.fragment","title":"<code>fragment: ndarray</code>  <code>property</code>","text":"<p>The slice of an image with the filtered coordinates in the format: image [pt1, pt2] where:</p> <ol> <li>pt1 = from point y to point y1</li> <li>pt2 = from point x to point x1</li> </ol>"},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage.lower_right_point","title":"<code>lower_right_point: tuple[float, float]</code>  <code>property</code>","text":"<p>The lower right point of a rectangle.</p>"},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage.upper_left_point","title":"<code>upper_left_point: tuple[float, float]</code>  <code>property</code>","text":"<p>The upper left point of a rectangle.</p>"},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage.x1","title":"<code>x1</code>  <code>property</code>","text":"<p>X-axis position marking end of filtered item.</p>"},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage.y1","title":"<code>y1</code>  <code>property</code>","text":"<p>Y-axis position marking end of filtered item.</p>"},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage-functions","title":"Functions","text":""},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage.greenbox","title":"<code>greenbox()</code>","text":"<p>Add a \"green box\" to the image where the box area is represented by the diagonal of pt1 and pt2: pt1 being the upper left point and pt2 being the lower right point of the rectangle.</p> Source code in <code>src/start_ocr/coordinates.py</code> Python<pre><code>def greenbox(self):\n    \"\"\"Add a \"green box\" to the image where the box area is represented by the\n    diagonal of pt1 and pt2: pt1 being the upper left point and pt2 being\n    the lower right point of the rectangle.\"\"\"\n    return cv2.rectangle(\n        img=self.im,\n        pt1=self.upper_left_point,\n        pt2=self.lower_right_point,\n        color=GREEN,\n        thickness=2,\n    )\n</code></pre>"},{"location":"coordinates/#start_ocr.coordinates.CoordinatedImage.redbox","title":"<code>redbox()</code>","text":"<p>Add a \"green box\" to the image where the box area is represented by the diagonal of pt1 and pt2: pt1 being the upper left point and pt2 being the lower right point of the rectangle.</p> Source code in <code>src/start_ocr/coordinates.py</code> Python<pre><code>def redbox(self):\n    \"\"\"Add a \"green box\" to the image where the box area is represented by the\n    diagonal of pt1 and pt2: pt1 being the upper left point and pt2 being\n    the lower right point of the rectangle.\"\"\"\n    return cv2.rectangle(\n        img=self.im,\n        pt1=self.upper_left_point,\n        pt2=self.lower_right_point,\n        color=PURPLE,\n        thickness=1,\n    )\n</code></pre>"},{"location":"measurements/","title":"Measurements","text":"<p>Since we'll be using distinct libraries with different formats, pay attention to the kind of measurements involved.</p>"},{"location":"measurements/#unit","title":"Unit","text":"Library Unit Description Maximum pdfplumber point PDF unit <code>page.height * page.width</code> is the size of the page opencv pixel Graphical unit <code>im.shape</code> gets a tuple of image dimensions <p>Warning</p> <p>Convert image's pixels as page points, by first getting image ratio; then apply ratio (percentage) to the page's max width / height.</p> Python<pre><code>&gt;&gt;&gt; from corpus_unpdf.src.common import get_contours # shortcut custom function\n&gt;&gt;&gt; im_h, im_w, im_d = im.shape # im_h is maximum image height\n&gt;&gt;&gt; test = next(cv2.boundingRect(c) for c in get_contours(im, (50, 10)))\n&gt;&gt;&gt; x, y, w, h = test # see Slicing below\n&gt;&gt;&gt; ratio = y / im_h # `y` coordinate over `im_h` gives a pixel-based ratio\n&gt;&gt;&gt; page_point = ratio * page.height # equivalent point in PDF page\n</code></pre> <p>See related discussion.</p>"},{"location":"measurements/#boxes","title":"Boxes","text":""},{"location":"measurements/#slicing-opencv","title":"Slicing opencv","text":"<p>Rectangles for opencv</p> Reference Expectation Format Unit cv2.boundingRect() Results in a tuple of four points (<code>x</code>,<code>y</code>,<code>w</code>,<code>h</code>) pixels Fields Meaning <code>x</code> point in x-axis <code>y</code> point in y-axis <code>w</code> width <code>h</code> height"},{"location":"measurements/#slicing-pdfplumber","title":"Slicing pdfplumber","text":"<p>Rectangles for pdfplumber</p> Reference Expectation Format Unit pdfplumber._typing.T_bbox A tuple of four points (<code>x0</code>, <code>y0</code>, <code>x1</code>, <code>y1</code>) points Fields Meaning <code>x0</code> left-most point in x-axis <code>x1</code> right-most point in x-axis <code>y0</code> top-most point in y-axis <code>y1</code> bottom-most point in y-axis"},{"location":"setup/","title":"Setup","text":""},{"location":"setup/#key-libraries","title":"Key Libraries","text":"Library Rationale Notes pdfplumber pdf to img to str Requires <code>Wand</code>, <code>Pillow</code>, <code>pdfminer.six</code>; Wand is dependent on <code>libmagickwand-dev</code> for APT on Debian/Ubuntu and <code>imagemagick</code> via homebrew Mac. opencv-python img manipulation Wrapper around OpenCV to apply changes to pdf-based images so that it can be prepared for OCR. pytesseract from img to str From the repo: Python-tesseract is a wrapper for Google's Tesseract-OCR Engine. It is also useful as a stand-alone invocation script to tesseract, as it can read all image types supported by the Pillow and Leptonica imaging libraries, including jpeg, png, gif, bmp, tiff, and others. Additionally, if used as a script, Python-tesseract will print the recognized text instead of writing it to a file."},{"location":"setup/#macos","title":"MacOS","text":""},{"location":"setup/#local-device","title":"Local Device","text":"<p>Install common libraries in MacOS with <code>homebrew</code>:</p> Bash<pre><code>brew install tesseract\nbrew install imagemagick\nbrew info imagemagick # check version\n</code></pre> <p>The last command shows the local folder where imagemagick is installed.</p> Bash<pre><code>==&gt; imagemagick: stable 7.1.1-17 (bottled), HEAD # note the version number\nTools and libraries to manipulate images in many formats\nhttps://imagemagick.org/index.php\n/opt/homebrew/Cellar/imagemagick/7.1.1-17 (807 files, 31MB) * # first part is the local folder\nx x x\n</code></pre>"},{"location":"setup/#virtual-environment","title":"Virtual Environment","text":"<p>Update <code>.env</code> whenever <code>imagemagick</code> changes</p> <p>The shared dependency is based on <code>MAGICK_HOME</code> folder. This can't seem to be fetched by python (at least in 3.11) so we need to help it along by explicitly declaring its location. The folder can change when a new version is installed via <code>brew upgrade imagemagick</code></p> <p>Create an .env file and use the folder as the environment variable <code>MAGICK_HOME</code>:</p> Text Only<pre><code>MAGICK_HOME=/opt/homebrew/Cellar/imagemagick/7.1.1-17\n</code></pre> <p>This configuration allows <code>pdfplumber</code> to detect <code>imagemagick</code>.</p> <p>Effect of not setting <code>MAGICK_HOME</code>:</p> Python<pre><code>&gt;&gt;&gt; import pdfplumber\n&gt;&gt;&gt; pdfplumber.open&lt;(testpath&gt;).pages[0].to_image(resolution=300) # ERROR\n</code></pre> Text Only<pre><code>OSError: cannot find library; tried paths: []\n\nDuring handling of the above exception, another exception occurred:\n\nImportError                               Traceback (most recent call last)\n...\nImportError: MagickWand shared library not found.\nYou probably had not installed ImageMagick library.\nTry to install:\n  brew install freetype imagemagick\n</code></pre> <p>With <code>MAGICK_HOME</code>:</p> Python<pre><code>&gt;&gt;&gt; import pdfplumber\n&gt;&gt;&gt; pdfplumber.open&lt;(testpath&gt;).pages[0].to_image\nPIL.Image.Image # image library and type detected\n</code></pre> <p>Create environment using <code>poetry install</code>:</p> TOML<pre><code>[tool.poetry.dependencies]\npython = \"^3.11\"\npython-dotenv = \"^1.0\"\npdfplumber = \"^0.9\"\npillow = \"^9.5\"\nopencv-python = \"^4.7\"\npytesseract = \"^0.3.10\"\n</code></pre>"},{"location":"setup/#pytest","title":"pytest","text":"<p>Ensure inclusion of <code>pytest-env</code></p> <p>Add to <code>pyproject.toml</code>:</p> TOML<pre><code>[tool.pytest.ini_options]\nenv = [\"MAGICK_HOME=/opt/homebrew/Cellar/imagemagick/7.1.1-17\"]\n</code></pre>"},{"location":"setup/#dockerfile","title":"Dockerfile","text":"<p>See resources:</p> <ol> <li>ImageMagick</li> <li>Stack Overflow, Ankur</li> <li>nickferrando Gist</li> <li>Stack Overflow, Shreyesh Desai</li> </ol> Docker<pre><code>ENV PYTHONDONTWRITEBYTECODE=1 \\\n  PYTHONUNBUFFERED=1 \\\n  MAGICK_HOME=/usr/local/lib/ImageMagick-$IM_VER\n\nRUN apt update \\\n  &amp;&amp; apt install -y \\\n    build-essential wget pkg-config \\\n    libxml2-dev zlib1g-dev \\\n    ghostscript tesseract-ocr tesseract-ocr-fra \\\n    libjpeg62-turbo-dev libtiff-dev libpng-dev libsm6 libxext6 ffmpeg libfontconfig1 libxrender1 libgl1-mesa-glx libfreetype6-dev \\\n  &amp;&amp; apt clean\n\nRUN mkdir -p /tmp/distr &amp;&amp; \\\n  cd /tmp/distr &amp;&amp; \\\n  wget https://download.imagemagick.org/ImageMagick/download/releases/ImageMagick-$IM_VER.tar.xz &amp;&amp; \\\n  tar xvf ImageMagick-$IM_VER.tar.xz &amp;&amp; \\\n  cd ImageMagick-$IM_VER &amp;&amp; \\\n  ./configure --enable-shared=yes --disable-static --without-perl &amp;&amp; \\\n  make &amp;&amp; \\\n  make install &amp;&amp; \\\n  ldconfig /usr/local/lib &amp;&amp; \\\n  cd /tmp &amp;&amp; \\\n  rm -rf distr\n\nRUN if [ -f $IM_POLICY ] ; then sed -i 's/&lt;policy domain=\"coder\" rights=\"none\" pattern=\"PDF\" \\/&gt;/&lt;policy domain=\"coder\" rights=\"read|write\" pattern=\"PDF\" \\/&gt;/g' $IM_POLICY ; else echo did not see file $IM_POLICY ; fi\n</code></pre> <p>The Dockerfile is intended for testing purposes:</p> Bash<pre><code>docker build --tag ocr . &amp;&amp; docker run ocr # will run pytest\n</code></pre>"},{"location":"setup/#github-actions","title":"Github Actions","text":"<p>Note that both <code>tesseract</code> and <code>imagemagick</code> libraries are also made preconditions in <code>.github/workflows/main.yaml</code>:</p> .github/workflows/main.yaml<pre><code>steps:\n  # see https://github.com/madmaze/pytesseract/blob/master/.github/workflows/ci.yaml\n  - name: Install tesseract\n    run: sudo apt-get -y update &amp;&amp; sudo apt-get install -y tesseract-ocr tesseract-ocr-fra\n  - name: Print tesseract version\n    run: echo $(tesseract --version)\n\n  # see https://github.com/jsvine/pdfplumber/blob/stable/.github/workflows/tests.yml\n  - name: Install ghostscript &amp; imagemagick\n    run: sudo apt update &amp;&amp; sudo apt install ghostscript libmagickwand-dev\n  - name: Remove policy.xml\n    run: sudo rm /etc/ImageMagick-6/policy.xml # this needs to be removed or the test won't run\n</code></pre>"},{"location":"slice/","title":"Slicing","text":""},{"location":"slice/#pagecut","title":"PageCut","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Fields:</p> field type description page pdfplumber.page.Page The page to cut x0 float or int The x axis where the slice will start x1 float or int The x axis where the slice will terminate y0 float or int The y axis where the slice will start y1 float or int The y axis where the slice will terminate <p>When the above fields are populated, the <code>@slice</code> property describes the area of the page that will be used to extract text from.</p> Source code in <code>src/start_ocr/slice.py</code> Python<pre><code>class PageCut(NamedTuple):\n    \"\"\"Fields:\n\n    field | type | description\n    --:|:--|:--\n    page | pdfplumber.page.Page | The page to cut\n    x0 | float or int | The x axis where the slice will start\n    x1 | float or int | The x axis where the slice will terminate\n    y0 | float or int | The y axis where the slice will start\n    y1 | float or int | The y axis where the slice will terminate\n\n    When the above fields are populated, the `@slice` property describes\n    the area of the page that will be used to extract text from.\n    \"\"\"\n\n    page: Page\n    x0: float | int\n    x1: float | int\n    y0: float | int\n    y1: float | int\n\n    @property\n    def slice(self) -&gt; CroppedPage:\n        \"\"\"Unlike slicing from an image based on a `np.ndarray`, a page cut\n        implies a page derived from `pdfplumber`. The former is based on pixels;\n        the latter on points.\n\n        Examples:\n            &gt;&gt;&gt; from pathlib import Path\n            &gt;&gt;&gt; from start_ocr.fetch import get_page_and_img\n            &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0) # page 1\n            &gt;&gt;&gt; page.height\n            936\n            &gt;&gt;&gt; cutpage = PageCut(page=page, x0=100, x1=200, y0=100, y1=200).slice\n            &gt;&gt;&gt; cutpage.height\n            100\n            &gt;&gt;&gt; page.pdf.close()\n\n        Returns:\n            CroppedPage: The page crop where to extract text from.\n        \"\"\"  # noqa: E501\n        box: T_bbox = (self.x0, self.y0, self.x1, self.y1)\n        return self.page.crop(box, relative=False, strict=True)\n\n    @classmethod\n    def set(cls, page: Page, y0: float | int, y1: float | int) -&gt; CroppedPage:\n        \"\"\"Using a uniform margin on the x-axis, supply the page\n        to generate page width and thus force preset margins. The `y0`\n        and `y1` fields determine how to slice the page.\n\n        Examples:\n            &gt;&gt;&gt; import pdfplumber\n            &gt;&gt;&gt; from pathlib import Path\n            &gt;&gt;&gt; from start_ocr.fetch import get_img_from_page\n            &gt;&gt;&gt; pdf = pdfplumber.open(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\")\n            &gt;&gt;&gt; page = pdf.pages[1] # page 2\n            &gt;&gt;&gt; im = get_img_from_page(page)\n            &gt;&gt;&gt; crop = PageCut.set(page, y0=0, y1=page.height * 0.1)\n            &gt;&gt;&gt; crop.extract_text()\n            'ALorem IpsumDocument 2 June1,2023'\n            &gt;&gt;&gt; pdf.close()\n\n        Args:\n            page (Page): pdfplumber Page object\n            y0 (float | int): Top y-axis\n            y1 (float | int): Bottom y-axis\n\n        Returns:\n            CroppedPage: The page crop where to extract text from.\n        \"\"\"  # noqa: E501\n        SIDE_MARGIN = 50\n        x0, x1 = SIDE_MARGIN, page.width - SIDE_MARGIN\n        cut = cls(page=page, x0=x0, x1=x1, y0=y0, y1=y1)\n        result = cut.slice\n        return result\n</code></pre>"},{"location":"slice/#start_ocr.slice.PageCut-attributes","title":"Attributes","text":""},{"location":"slice/#start_ocr.slice.PageCut.slice","title":"<code>slice: CroppedPage</code>  <code>property</code>","text":"<p>Unlike slicing from an image based on a <code>np.ndarray</code>, a page cut implies a page derived from <code>pdfplumber</code>. The former is based on pixels; the latter on points.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from start_ocr.fetch import get_page_and_img\n&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0) # page 1\n&gt;&gt;&gt; page.height\n936\n&gt;&gt;&gt; cutpage = PageCut(page=page, x0=100, x1=200, y0=100, y1=200).slice\n&gt;&gt;&gt; cutpage.height\n100\n&gt;&gt;&gt; page.pdf.close()\n</code></pre> <p>Returns:</p> Name Type Description <code>CroppedPage</code> <code>CroppedPage</code> <p>The page crop where to extract text from.</p>"},{"location":"slice/#start_ocr.slice.PageCut-functions","title":"Functions","text":""},{"location":"slice/#start_ocr.slice.PageCut.set","title":"<code>set(page, y0, y1)</code>  <code>classmethod</code>","text":"<p>Using a uniform margin on the x-axis, supply the page to generate page width and thus force preset margins. The <code>y0</code> and <code>y1</code> fields determine how to slice the page.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; import pdfplumber\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from start_ocr.fetch import get_img_from_page\n&gt;&gt;&gt; pdf = pdfplumber.open(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\")\n&gt;&gt;&gt; page = pdf.pages[1] # page 2\n&gt;&gt;&gt; im = get_img_from_page(page)\n&gt;&gt;&gt; crop = PageCut.set(page, y0=0, y1=page.height * 0.1)\n&gt;&gt;&gt; crop.extract_text()\n'ALorem IpsumDocument 2 June1,2023'\n&gt;&gt;&gt; pdf.close()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>Page</code> <p>pdfplumber Page object</p> required <code>y0</code> <code>float | int</code> <p>Top y-axis</p> required <code>y1</code> <code>float | int</code> <p>Bottom y-axis</p> required <p>Returns:</p> Name Type Description <code>CroppedPage</code> <code>CroppedPage</code> <p>The page crop where to extract text from.</p> Source code in <code>src/start_ocr/slice.py</code> Python<pre><code>@classmethod\ndef set(cls, page: Page, y0: float | int, y1: float | int) -&gt; CroppedPage:\n    \"\"\"Using a uniform margin on the x-axis, supply the page\n    to generate page width and thus force preset margins. The `y0`\n    and `y1` fields determine how to slice the page.\n\n    Examples:\n        &gt;&gt;&gt; import pdfplumber\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from start_ocr.fetch import get_img_from_page\n        &gt;&gt;&gt; pdf = pdfplumber.open(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\")\n        &gt;&gt;&gt; page = pdf.pages[1] # page 2\n        &gt;&gt;&gt; im = get_img_from_page(page)\n        &gt;&gt;&gt; crop = PageCut.set(page, y0=0, y1=page.height * 0.1)\n        &gt;&gt;&gt; crop.extract_text()\n        'ALorem IpsumDocument 2 June1,2023'\n        &gt;&gt;&gt; pdf.close()\n\n    Args:\n        page (Page): pdfplumber Page object\n        y0 (float | int): Top y-axis\n        y1 (float | int): Bottom y-axis\n\n    Returns:\n        CroppedPage: The page crop where to extract text from.\n    \"\"\"  # noqa: E501\n    SIDE_MARGIN = 50\n    x0, x1 = SIDE_MARGIN, page.width - SIDE_MARGIN\n    cut = cls(page=page, x0=x0, x1=x1, y0=y0, y1=y1)\n    result = cut.slice\n    return result\n</code></pre>"},{"location":"slice/#get_likelihood_centered_coordinates","title":"<code>get_likelihood_centered_coordinates()</code>","text":"<p>With a image <code>im</code>, get all contours found in the center of the image and then for each of these matches, if they are text resembling <code>text_to_match</code>, extract the coordinates of such contours.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from start_ocr.fetch import get_page_and_img\n&gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n&gt;&gt;&gt; get_likelihood_centered_coordinates(im, 'Decision') # None found\n&gt;&gt;&gt; res = get_likelihood_centered_coordinates(im, 'Memo')\n&gt;&gt;&gt; isinstance(res, tuple)\nTrue\n&gt;&gt;&gt; page.pdf.close()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>im</code> <code>ndarray</code> <p>The base image to look for text</p> required <code>text_to_match</code> <code>str</code> <p>The words that should match</p> required <p>Returns:</p> Type Description <code>tuple[int, int, int, int] | None</code> <p>tuple[int, int, int, int] | None: (x, y, w, h) pixels representing <code>cv2.boundingRect</code>, if found.</p> Source code in <code>src/start_ocr/slice.py</code> Python<pre><code>def get_likelihood_centered_coordinates(\n    im: np.ndarray, text_to_match: str\n) -&gt; tuple[int, int, int, int] | None:\n    \"\"\"With a image `im`, get all contours found in the center\n    of the image and then for each of these matches, if they\n    are text resembling `text_to_match`, extract the coordinates of\n    such contours.\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from start_ocr.fetch import get_page_and_img\n        &gt;&gt;&gt; page, im = get_page_and_img(Path().cwd() / \"tests\" / \"data\" / \"lorem_ipsum.pdf\", 0)\n        &gt;&gt;&gt; get_likelihood_centered_coordinates(im, 'Decision') # None found\n        &gt;&gt;&gt; res = get_likelihood_centered_coordinates(im, 'Memo')\n        &gt;&gt;&gt; isinstance(res, tuple)\n        True\n        &gt;&gt;&gt; page.pdf.close()\n\n    Args:\n        im (np.ndarray): The base image to look for text\n        text_to_match (str): The words that should match\n\n    Returns:\n        tuple[int, int, int, int] | None: (x, y, w, h) pixels representing\n            `cv2.boundingRect`, if found.\n    \"\"\"  # noqa: E501\n    _, im_w, _ = im.shape\n    for cnt in get_contours(im, (50, 50)):\n        x, y, w, h = cv2.boundingRect(cnt)\n        x0_mid_left = (1 * im_w) / 4 &lt; x\n        endpoint_on_right = x + w &gt; im_w / 2\n        short_width = w &gt; 200\n        if all([x0_mid_left, endpoint_on_right, short_width]):\n            # cv2.rectangle(im, (x, y), (x + w, y + h), (36, 255, 12), 3)\n            # cv2.imwrite(\"temp/sample_boxes.png\", im)\n            if is_match_text(\n                sliced_im=im[y : y + h, x : x + w],\n                text_to_match=text_to_match,\n                likelihood=0.7,\n            ):\n                return x, y, w, h\n    return None\n</code></pre>"},{"location":"slice/#is_match_text","title":"<code>is_match_text()</code>","text":"<p>Test whether textual image in <code>sliced_im</code> resembles <code>text_to_match</code> by a <code>likelihood</code> percentage.</p> <p>Parameters:</p> Name Type Description Default <code>sliced_im</code> <code>ndarray</code> <p>Slice of a larger image containing text</p> required <code>text_to_match</code> <code>str</code> <p>How to match the text slice in <code>im</code></p> required <code>likelihood</code> <code>float</code> <p>Allowed percentage expressed in decimals</p> <code>0.7</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether or not the <code>text_to_match</code> resembles <code>sliced_im</code>'s text.</p> Source code in <code>src/start_ocr/slice.py</code> Python<pre><code>def is_match_text(\n    sliced_im: np.ndarray,\n    text_to_match: str,\n    likelihood: float = 0.7,\n) -&gt; bool:\n    \"\"\"Test whether textual image in `sliced_im` resembles `text_to_match` by\n    a `likelihood` percentage.\n\n    Args:\n        sliced_im (np.ndarray): Slice of a larger image containing text\n        text_to_match (str): How to match the text slice in `im`\n        likelihood (float): Allowed percentage expressed in decimals\n\n    Returns:\n        bool: Whether or not the `text_to_match` resembles `sliced_im`'s text.\n    \"\"\"\n    upper_candidate = pytesseract.image_to_string(sliced_im).strip().upper()\n    upper_matcher = text_to_match.upper()\n    match = SequenceMatcher(None, a=upper_candidate, b=upper_matcher)\n    return match.ratio() &gt; likelihood\n</code></pre>"}]}